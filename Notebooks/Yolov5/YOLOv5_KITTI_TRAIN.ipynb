{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLByKKd-rb9g"
      },
      "source": [
        "# To train and test Yolov5, the first clone the repository. All dependencies must be installed an imported as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4HlaKnKqWSz",
        "outputId": "c120801f-3918-4e42-dd57-4787786520bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 10893, done.\u001b[K\n",
            "remote: Total 10893 (delta 0), reused 0 (delta 0), pack-reused 10893\u001b[K\n",
            "Receiving objects: 100% (10893/10893), 12.39 MiB | 26.43 MiB/s, done.\n",
            "Resolving deltas: 100% (7532/7532), done.\n",
            "/content/yolov5\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.21.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Collecting PyYAML>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.63.0)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.8.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.11.2)\n",
            "Collecting thop\n",
            "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (3.10.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.44.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 20)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.2.0)\n",
            "Installing collected packages: thop, PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/achelm15/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt\n",
        "import pathlib\n",
        "import os\n",
        "import cv2\n",
        "import zipfile\n",
        "from os import path\n",
        "import shutil\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import glob\n",
        "from shutil import copyfile\n",
        "from PIL import Image\n",
        "from math import floor, ceil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIH3wuOssEi2"
      },
      "source": [
        "# The next cells contain necessary steps to train the model on the Kitti dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL5k0gNWsXM4"
      },
      "outputs": [],
      "source": [
        "#creates a yaml file to train YOLOv5 on the Kitti dataset\n",
        "data = open(\"data.yaml\", \"w\")\n",
        "data.write(\"train: ./kittiyolo/train/images\\nval: ./kittiyolo/valid/images\\nnc: 8\\nnames: [\\'Car\\', \\'Pedestrian\\', \\'Cyclist\\', \\'Van\\', \\'Truck\\', \\'Person_sitting\\', \\'Tram\\', \\'DontCare\\']\")\n",
        "data.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMVF5QvuqegM",
        "outputId": "a8a1b95e-6e1e-4879-fac4-3fa5f000673c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-07 18:23:44--  https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_image_2.zip\n",
            "Resolving s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)... 52.219.171.17\n",
            "Connecting to s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)|52.219.171.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12569945557 (12G) [application/zip]\n",
            "Saving to: ‘kitti.zip’\n",
            "\n",
            "kitti.zip           100%[===================>]  11.71G  30.3MB/s    in 6m 59s  \n",
            "\n",
            "2022-04-07 18:30:45 (28.6 MB/s) - ‘kitti.zip’ saved [12569945557/12569945557]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#downloads the kitti images in a zip file\n",
        "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_image_2.zip -O kitti.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdYuYkHkqgSQ",
        "outputId": "e2817d7f-fce3-4c84-bf77-18e2cb9f135e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-07 18:30:45--  https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_label_2.zip\n",
            "Resolving s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)... 52.219.169.81\n",
            "Connecting to s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)|52.219.169.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5601213 (5.3M) [application/zip]\n",
            "Saving to: ‘kittilabel.zip’\n",
            "\n",
            "kittilabel.zip      100%[===================>]   5.34M  6.70MB/s    in 0.8s    \n",
            "\n",
            "2022-04-07 18:30:46 (6.70 MB/s) - ‘kittilabel.zip’ saved [5601213/5601213]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#downloads the kitti labels in a zip file\n",
        "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_label_2.zip -O kittilabel.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwQOtIesqhu9"
      },
      "outputs": [],
      "source": [
        "# unzips both the images and labels\n",
        "with zipfile.ZipFile(\"./kitti.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"kitti\")\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"./kittilabel.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"kittilabel\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRibzG6hvZjA"
      },
      "source": [
        "The next few boxes convert the original labels of the Kitti dataset to a form that YOLOv5 is able to use. If you wish to understand this transformation, open a Kitti label file before running the next few cells, and then open the corresponding file after running the cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JC8KcE3qjwq"
      },
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path('kitti/training/image_2')\n",
        "label_dir = pathlib.Path('kitti/training/label_2')\n",
        "yolo_labels = pathlib.Path('yolo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_0KAsQHqlTq"
      },
      "outputs": [],
      "source": [
        "image_count = len(list(data_dir.glob('*.png')))\n",
        "label_count = len(list(label_dir.glob('*.txt')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1xEBiCvxIsy",
        "outputId": "4df90864-dc4a-4be5-a0ef-e54e86897332"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7481"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(list(pathlib.Path('./kittilabel/training/label_2').glob('*txt')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIgRpwpQqmpC"
      },
      "outputs": [],
      "source": [
        "root_path = \"./kitti/training/\"\n",
        "yolo_path = \"yolo/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lyujdOfqobb"
      },
      "outputs": [],
      "source": [
        "kitti2yolotype_dict = {\n",
        "    \"Car\": \"0\",\n",
        "    \"Van\": \"0\",\n",
        "    \"Pedestrian\": \"1\",\n",
        "    \"Person_sitting\": \"1\",\n",
        "    \"Cyclist\": \"2\",\n",
        "    \"Truck\": \"3\",\n",
        "    \"Tram\": \"6\",\n",
        "    \"Misc\": \"6\",\n",
        "    \"DontCare\": \"6\",\n",
        "}\n",
        "def kitti2yolo(kitti_label, img_height, img_width):\n",
        "\n",
        "    kitti_label_arr = kitti_label.split(\" \")\n",
        "    x1 = float(kitti_label_arr[4])\n",
        "    y1 = float(kitti_label_arr[5])\n",
        "    x2 = float(kitti_label_arr[6])\n",
        "    y2 = float(kitti_label_arr[7])\n",
        "\n",
        "    bb_width = x2 - x1\n",
        "    bb_height = y2 - y1\n",
        "    yolo_x = (x1 + 0.5 * bb_width) / img_width\n",
        "    yolo_y = (y1 + 0.5 * bb_height) / img_height\n",
        "    yolo_bb_width = bb_width / img_width\n",
        "    yolo_bb_height = bb_height / img_height\n",
        "    yolo_label = kitti2yolotype_dict[kitti_label_arr[0]]\n",
        "\n",
        "    return (\n",
        "        yolo_label\n",
        "        + \" \"\n",
        "        + str(yolo_x)\n",
        "        + \" \"\n",
        "        + str(yolo_y)\n",
        "        + \" \"\n",
        "        + str(yolo_bb_width)\n",
        "        + \" \"\n",
        "        + str(yolo_bb_height)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6sGd0QnqpyG"
      },
      "outputs": [],
      "source": [
        "%cp -r kittilabel/training/label_2 kitti/training/label_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsxqzEuqqrTu"
      },
      "outputs": [],
      "source": [
        "kitti_images_path = root_path + \"image_2\" + os.sep\n",
        "kitti_labels_path = root_path + \"label_2\" + os.sep\n",
        "\n",
        "# yolo paths\n",
        "if yolo_path is None:\n",
        "    yolo_path = root_path + \"yolo_labels\" + os.sep\n",
        "\n",
        "if not os.path.exists(yolo_path):\n",
        "    os.makedirs(yolo_path)\n",
        "\n",
        "# load each kitti label, convert to yolo and save\n",
        "for labelfilename in os.listdir(kitti_labels_path):\n",
        "  yolo_labels = []\n",
        "  with open(kitti_labels_path + labelfilename, \"r\") as kittilabelfile:\n",
        "    cvimage = cv2.imread(\n",
        "        kitti_images_path + labelfilename.split(\".txt\")[0] + \".png\"\n",
        "        )\n",
        "    height, width, frame_depth = cvimage.shape\n",
        "    for kitti_label in kittilabelfile:\n",
        "      yolo_labels.append(\n",
        "          kitti2yolo(kitti_label, img_height=height, img_width=width)\n",
        "          )\n",
        "      with open(yolo_path + labelfilename, \"w+\") as yololabelfile:\n",
        "        for label in yolo_labels:\n",
        "          yololabelfile.write(label + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao4SuLz0vxV8"
      },
      "source": [
        "The next cells move the correct YOLOv5 labels to a directory so they can be used to train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0ULjL9_qsiQ",
        "outputId": "77112851-4686-4672-cfa3-92f0fb06d271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5/kittiyolo\n",
            "/content/yolov5/kittiyolo/valid\n",
            "/content/yolov5\n"
          ]
        }
      ],
      "source": [
        "%mkdir kittiyolo\n",
        "%cd kittiyolo\n",
        "%mkdir train\n",
        "%mkdir valid\n",
        "%cd valid\n",
        "%mkdir images\n",
        "%mkdir labels\n",
        "%cd ../.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3r3vn6x-qts1"
      },
      "outputs": [],
      "source": [
        "%cp -r yolo kittiyolo/train/labels\n",
        "%cp -r kitti/training/image_2 kittiyolo/train/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvgWs8kPqvHO"
      },
      "outputs": [],
      "source": [
        "root_path = \"./kittiyolo/train/\"\n",
        "kittiyolo_images_path = root_path + \"images\" + os.sep\n",
        "kittiyolo_labels_path = root_path + \"labels\" + os.sep\n",
        "yolo_valid_path = \"./yolo/valid\"\n",
        "\n",
        "# load each kitti label, convert to yolo and save\n",
        "count = 0\n",
        "for labelfilename in os.listdir(kittiyolo_images_path):\n",
        "  count = count+1\n",
        "  if count == 3:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51SAINbsqyIO"
      },
      "outputs": [],
      "source": [
        "def moveFiles(src, dst):\n",
        "  files = []\n",
        "  for i in os.listdir(src):\n",
        "    files.append(i)\n",
        "  files = sorted(files)\n",
        "  listt = np.random.RandomState(seed=42).permutation(files)[:1000]\n",
        "  for f in listt:\n",
        "    shutil.copy(os.path.join(src, f), dst)\n",
        "    p = os.path.join(src, f)\n",
        "    os.remove(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1KrVa-jqzs9"
      },
      "outputs": [],
      "source": [
        "moveFiles(\"kittiyolo/train/images\", \"kittiyolo/valid/images\")\n",
        "moveFiles(\"kittiyolo/train/labels\", \"kittiyolo/valid/labels\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjfjO6cv3iCq"
      },
      "source": [
        "#Used to augment the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMlZdeSbCRZN"
      },
      "outputs": [],
      "source": [
        "%cp -r kittiyolo kittiyolosave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVJZe2NSImLC"
      },
      "outputs": [],
      "source": [
        "%rm -r kittiyolo\n",
        "%cp -r kittiyolosave kittiyolo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vdNESDTGfgw",
        "outputId": "b45cbb64-11de-4078-85bd-0ded9bd9402f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6481\n",
            "6481\n",
            "1000\n",
            "1000\n"
          ]
        }
      ],
      "source": [
        "%ls kittiyolo/train/images | wc -l\n",
        "%ls kittiyolo/train/labels | wc -l\n",
        "%ls kittiyolo/valid/images | wc -l\n",
        "%ls kittiyolo/valid/labels | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaBZityf3hWL"
      },
      "outputs": [],
      "source": [
        "def contrast_image(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.random_contrast(img, 2, 5, 42)\n",
        "    img = img.numpy()\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    copy_label(image, \"contrast\", folder)\n",
        "def noise_image(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.stateless_random_jpeg_quality(img, 2, 20, (42,42))\n",
        "    img = img.numpy()\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    copy_label(image, \"noise\", folder)\n",
        "def grayscale_image(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.rgb_to_grayscale(img)\n",
        "    img = img.numpy()\n",
        "    img = img.reshape((img.shape[0], img.shape[1]))\n",
        "    im = Image.fromarray(img, 'L')\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    copy_label(image, \"grayscale\", folder)\n",
        "def saturate_image(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.random_saturation(img, 2, 120, 42)\n",
        "    img = img.numpy()\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    copy_label(image, \"saturate\", folder)\n",
        "def hue_image(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.random_hue(img, 0.1)\n",
        "    img = img.numpy()\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    copy_label(image, \"hue\", folder)\n",
        "def flip_image_lr(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.flip_left_right(img)\n",
        "    img = img.numpy()\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    flip_label_lr(image[:image.find('.')]+\".txt\", image[:image.find('.')]+\"_flip_lr.txt\", folder)\n",
        "def flip_image_ud(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.flip_up_down(img)\n",
        "    img = img.numpy()\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    flip_label_ud(image[:image.find('.')]+\".txt\", image[:image.find('.')]+\"_flip_ud.txt\", folder)\n",
        "def rot_90(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.rot90(img)\n",
        "    img = img.numpy()\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    label_rot_90(image[:image.find('.')]+\".txt\", image[:image.find('.')]+\"_rot_90.txt\", folder)\n",
        "def crop_bbox(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    width = img.shape[1]\n",
        "    height = img.shape[0]\n",
        "    label_file = folder+\"/labels/\"+image[:image.find('.')]+\".txt\"\n",
        "    ball_list = []\n",
        "    with open(label_file) as f:\n",
        "        count = 0\n",
        "        lines = f.readlines()\n",
        "        new_lines = []\n",
        "        for x in lines:\n",
        "            words = x.split(\" \")\n",
        "            if words[0]==\"1\":\n",
        "                ball_list.append(words)\n",
        "                xp = float(words[1])\n",
        "                yp = float(words[2])\n",
        "                wp = float(words[3])\n",
        "                hp = float(words[4])\n",
        "                x1 = int(floor(xp*width-(wp*width)/2))\n",
        "                y1 = int(floor(yp*height-(hp*height)/2))\n",
        "                image = tf.image.crop_to_bounding_box(img,y1,x1,int(ceil(hp*height)),int(ceil(wp*width)))\n",
        "                image = image.numpy()\n",
        "                im = Image.fromarray(image)\n",
        "                file = new_image[0:new_image.find('.')]+\"_\"+str(count)+new_image[new_image.find('.'):]\n",
        "                im.save(folder+'/images/'+file)\n",
        "                new_label_file = file[:file.find('.')]+\".txt\"\n",
        "                bb_crop_label(new_label_file, folder)\n",
        "                count += 1\n",
        "def bb_crop_label(new_label_file, folder):\n",
        "    with open(folder+'/labels/'+new_label_file, 'w') as f:\n",
        "        f.write(\"1 0.5 0.5 1.0 1.0\")\n",
        "def flip_label_lr(label_file, new_label_file, folder):\n",
        "    label_file = folder+\"/labels/\"+label_file\n",
        "    new_label_file = folder+\"/labels/\"+new_label_file\n",
        "    with open(label_file) as f:\n",
        "        lines = f.readlines()\n",
        "        new_lines = []\n",
        "        for x in lines:\n",
        "            words = x.split(\" \")\n",
        "            words[1] = str(1-float(words[1]))\n",
        "            new_lines.append(\" \".join(words))\n",
        "    f.close()\n",
        "    with open(new_label_file, 'w') as f:\n",
        "        for x in new_lines:\n",
        "            f.write(x)\n",
        "def flip_label_ud(label_file, new_label_file, folder):\n",
        "    label_file = folder+\"/labels/\"+label_file\n",
        "    new_label_file = folder+\"/labels/\"+new_label_file\n",
        "    with open(label_file) as f:\n",
        "        lines = f.readlines()\n",
        "        new_lines = []\n",
        "        for x in lines:\n",
        "            words = x.split(\" \")\n",
        "            words[2] = str(1-float(words[2]))\n",
        "            new_lines.append(\" \".join(words))\n",
        "    f.close()\n",
        "    with open(new_label_file, 'w') as f:\n",
        "        for x in new_lines:\n",
        "            f.write(x)\n",
        "def label_rot_90(label_file, new_label_file, folder):\n",
        "    label_file = folder+\"/labels/\"+label_file\n",
        "    new_label_file = folder+\"/labels/\"+new_label_file\n",
        "    with open(label_file) as f:\n",
        "        lines = f.readlines()\n",
        "        new_lines = []\n",
        "        for x in lines:\n",
        "            words = x.split(\" \")\n",
        "            x = words[1]\n",
        "            y = words[2]\n",
        "            w = words[3]\n",
        "            h = words[4]\n",
        "            words[1] = y\n",
        "            words[2] = str(1-float(x))\n",
        "            words[3] = h\n",
        "            words[4] = w\n",
        "            new_lines.append(\" \".join(words))\n",
        "    f.close()\n",
        "    with open(new_label_file, 'w') as f:\n",
        "        for x in new_lines:\n",
        "            f.write(x)\n",
        "def copy_label(image, augmentation, folder):\n",
        "    filename = image[:image.find('.')]\n",
        "    new_filename = folder+'/labels/'+filename+'_'+augmentation+'.txt'\n",
        "    filename = folder+'/labels/'+filename+'.txt'\n",
        "    copyfile(filename, new_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gh5VY67m3mcf"
      },
      "outputs": [],
      "source": [
        "# aug_list = ['_cropped', '_contrast', '_noise', '_flip_lr', '_flip_ud', '_rot_90', '_saturate', '_hue']\n",
        "# aug_list = ['_contrast', '_noise' '_saturate']\n",
        "aug_list = ['_noise']\n",
        "data_dir = \"./kittiyolo/train\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWl0QdDG3vCw"
      },
      "outputs": [],
      "source": [
        "for root, dirs, files in os.walk(data_dir+'/images/', topdown=False):\n",
        "  for file in files:\n",
        "    count = 0\n",
        "    for j in aug_list:\n",
        "      filename = file[:file.find('.')]+j+file[file.find('.'):]\n",
        "      # if count==0: contrast_image(file, filename, data_dir)\n",
        "      # if count==1: noise_image(file, filename, data_dir)\n",
        "      # if count==2: saturate_image(file, filename, data_dir)\n",
        "      noise_image(file, filename, data_dir)\n",
        "      count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rakqm0xsXYUj"
      },
      "outputs": [],
      "source": [
        "for root, dirs, files in os.walk(data_dir+'/images/', topdown=False):\n",
        "    for file in files:\n",
        "        filename = file[:file.find('.')]+\"_saturate\"+file[file.find('.'):]\n",
        "        saturate_image(file, filename, data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi2KuKCeA8QT"
      },
      "outputs": [],
      "source": [
        "%cp -r kittiyolorestart kittiyolo/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CFOcCDgt8GE"
      },
      "source": [
        "# The next cell can be used to train the dataset on the small version of YOLOv5. \n",
        "Changing the parameters might lead to improved performance. See the detect.py file for information on parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "778i_ZvMq7mr"
      },
      "outputs": [],
      "source": [
        "!python train.py --img 320 --batch 175 --epochs 350 --data ./data.yaml --weights \"yolov5s.pt\" --project modified --freeze 1 3 5 7 9 --changes 2,4,6,8,13 --hyp data/hyps/hyp.finetune.yaml "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c71FEvvjli91"
      },
      "outputs": [],
      "source": [
        "!python val.py --weights \"modified/train/exp/best.pt\" --img 320 --data data.yaml"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "iLByKKd-rb9g",
        "iIH3wuOssEi2",
        "TjfjO6cv3iCq"
      ],
      "machine_shape": "hm",
      "name": "YOLOv5_KITTI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}