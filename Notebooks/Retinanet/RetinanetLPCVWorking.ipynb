{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RetinanetLPCVWorking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qUWN-1Xy2yk"
      },
      "source": [
        "!git clone https://github.com/fizyr/keras-retinanet.git\n",
        "%cd keras-retinanet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzSeir5yYtFc"
      },
      "source": [
        "!pip install Pillow\n",
        "!pip install -r requirements.txt\n",
        "!pip install . --user\n",
        "!python setup.py build_ext --inplac"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdVnAwZSDPkz"
      },
      "source": [
        "#Upload Zipped LPCV Data to proceed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HD9OJHwCt6q"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import glob\n",
        "from shutil import copyfile\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZtRQFc6qdkH"
      },
      "source": [
        "%rm -r LPCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ48bcCaCVZp"
      },
      "source": [
        "!unzip LPCVtrain.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO-c2pnsDLWn"
      },
      "source": [
        "%mkdir ./LPCV/valid\n",
        "%mkdir ./LPCV/valid/images\n",
        "%mkdir ./LPCV/valid/labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB8OainqxJAd"
      },
      "source": [
        "data = open(\"LPCV/dataset.txt\", \"w\")\n",
        "data.write(\"Person,0\\nBall,1\")\n",
        "data.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaJpO7dUDqbR"
      },
      "source": [
        "def contrast_image(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.random_contrast(img, 2, 5, 42)\n",
        "    img = img.numpy()\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    copy_label(image, \"contrast\", folder)\n",
        "def noise_image(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.stateless_random_jpeg_quality(img, 2, 20, (42,42))\n",
        "    img = img.numpy()\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    copy_label(image, \"noise\", folder)\n",
        "def grayscale_image(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.rgb_to_grayscale(img)\n",
        "    img = img.numpy()\n",
        "    img = img.reshape((img.shape[0], img.shape[1]))\n",
        "    im = Image.fromarray(img, 'L')\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    copy_label(image, \"grayscale\", folder)\n",
        "def saturate_image(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.random_saturation(img, 2, 120, 42)\n",
        "    img = img.numpy()\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    copy_label(image, \"saturate\", folder)\n",
        "def hue_image(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.random_hue(img, 0.1)\n",
        "    img = img.numpy()\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    copy_label(image, \"hue\", folder)\n",
        "def flip_image_lr(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.flip_left_right(img)\n",
        "    img = img.numpy()\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    flip_label_lr(image[:image.find('.')]+\".txt\", image[:image.find('.')]+\"_flip_lr.txt\", folder)\n",
        "def flip_image_ud(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.flip_up_down(img)\n",
        "    img = img.numpy()\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    flip_label_ud(image[:image.find('.')]+\".txt\", image[:image.find('.')]+\"_flip_ud.txt\", folder)\n",
        "def rot_90(image, new_image, folder):\n",
        "    img = Image.open(folder+'/images/'+image)\n",
        "    img = np.array(img)\n",
        "    img = tf.image.rot90(img)\n",
        "    img = img.numpy()\n",
        "    im = Image.fromarray(img)\n",
        "    im.save(folder+'/images/'+new_image)\n",
        "    label_rot_90(image[:image.find('.')]+\".txt\", image[:image.find('.')]+\"_rot_90.txt\", folder)\n",
        "def flip_label_lr(label_file, new_label_file, folder):\n",
        "    label_file = folder+\"/labels/\"+label_file\n",
        "    new_label_file = folder+\"/labels/\"+new_label_file\n",
        "    with open(label_file) as f:\n",
        "        lines = f.readlines()\n",
        "        new_lines = []\n",
        "        for x in lines:\n",
        "            words = x.split(\" \")\n",
        "            words[1] = str(1-float(words[1]))\n",
        "            new_lines.append(\" \".join(words))\n",
        "    f.close()\n",
        "    with open(new_label_file, 'w') as f:\n",
        "        for x in new_lines:\n",
        "            f.write(x)\n",
        "def flip_label_ud(label_file, new_label_file, folder):\n",
        "    label_file = folder+\"/labels/\"+label_file\n",
        "    new_label_file = folder+\"/labels/\"+new_label_file\n",
        "    with open(label_file) as f:\n",
        "        lines = f.readlines()\n",
        "        new_lines = []\n",
        "        for x in lines:\n",
        "            words = x.split(\" \")\n",
        "            words[2] = str(1-float(words[2]))\n",
        "            new_lines.append(\" \".join(words))\n",
        "    f.close()\n",
        "    with open(new_label_file, 'w') as f:\n",
        "        for x in new_lines:\n",
        "            f.write(x)\n",
        "def label_rot_90(label_file, new_label_file, folder):\n",
        "    label_file = folder+\"/labels/\"+label_file\n",
        "    new_label_file = folder+\"/labels/\"+new_label_file\n",
        "    with open(label_file) as f:\n",
        "        lines = f.readlines()\n",
        "        new_lines = []\n",
        "        for x in lines:\n",
        "            words = x.split(\" \")\n",
        "            x = words[1]\n",
        "            y = words[2]\n",
        "            w = words[3]\n",
        "            h = words[4]\n",
        "            words[1] = y\n",
        "            words[2] = str(1-float(x))\n",
        "            words[3] = h\n",
        "            words[4] = w\n",
        "            new_lines.append(\" \".join(words))\n",
        "            # new_lines.append(\" \".join(words[:len(words)-1]))\n",
        "    f.close()\n",
        "    with open(new_label_file, 'w') as f:\n",
        "        for x in new_lines:\n",
        "            f.write(x)\n",
        "def copy_label(image, augmentation, folder):\n",
        "    filename = image[:image.find('.')]\n",
        "    new_filename = folder+'/labels/'+filename+'_'+augmentation+'.txt'\n",
        "    filename = folder+'/labels/'+filename+'.txt'\n",
        "    copyfile(filename, new_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ienh5ZqRDtEI"
      },
      "source": [
        "aug_list = ['_contrast', '_noise', '_flip_lr', '_flip_ud', '_rot_90', '_saturate', '_hue']\n",
        "data_dir = \"./LPCV/train\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMezns9iDvL8"
      },
      "source": [
        "for root, dirs, files in os.walk(data_dir+'/images/', topdown=False):\n",
        "    for file in files:\n",
        "      count = 0\n",
        "      for j in aug_list:\n",
        "        filename = file[:file.find('.')]+j+file[file.find('.'):]\n",
        "        if count==0: contrast_image(file, filename, data_dir)\n",
        "        if count==1: noise_image(file, filename, data_dir)\n",
        "        if count==2: flip_image_lr(file, filename, data_dir)\n",
        "        if count==3: flip_image_ud(file, filename, data_dir)\n",
        "        if count==4: rot_90(file, filename, data_dir)\n",
        "        if count==5: saturate_image(file, filename, data_dir)\n",
        "        if count==6: hue_image(file, filename, data_dir)\n",
        "        count+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP3EKfG7DwGl"
      },
      "source": [
        "for root, dirs, files in os.walk(data_dir+'/images/', topdown=False):\n",
        "    for file in files:\n",
        "        filename = file[:file.find('.')]+\"_grayscale\"+file[file.find('.'):]\n",
        "        grayscale_image(file, filename, data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXvWoK_hD0qg"
      },
      "source": [
        "def moveFiles(src, dst):\n",
        "  files = []\n",
        "  for i in os.listdir(src):\n",
        "    if i.find(\"contrast\")==-1 and i.find(\"hue\")==-1 and i.find(\"flip\")==-1 and i.find(\"gray\")==-1 and i.find(\"noise\")==-1 and i.find(\"rot\")==-1 and i.find(\"saturate\")==-1:\n",
        "      files.append(i)\n",
        "  files = sorted(files)\n",
        "  listt = np.random.RandomState(seed=12).permutation(files)[:30]\n",
        "  for f in listt:\n",
        "    shutil.copy(os.path.join(src, f), dst)\n",
        "    p = os.path.join(src, f)\n",
        "    os.remove(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WERmj-ED3I0"
      },
      "source": [
        "moveFiles(\"LPCV/train/images\", \"LPCV/valid/images\")\n",
        "moveFiles(\"LPCV/train/labels\", \"LPCV/valid/labels\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU-Hc8P4Mm-9"
      },
      "source": [
        "def create_annotations(data_dir):\n",
        "  for root, dirs, files in os.walk(data_dir+'/labels/', topdown=False):\n",
        "      new_lines = []\n",
        "      for file in files:\n",
        "          im_name = file[:len(file)-3]+\"jpg\"\n",
        "          if im_name.find('grayscale')==-1:\n",
        "              im = cv2.imread(data_dir+\"/images/\"+im_name)\n",
        "              height = im.shape[0]\n",
        "              width = im.shape[1]\n",
        "          else:\n",
        "              im = cv2.imread(data_dir+\"/images/\"+im_name, cv2.IMREAD_GRAYSCALE)\n",
        "              height = im.shape[0]\n",
        "              width = im.shape[1]\n",
        "          with open(data_dir+'/labels/'+file) as f:\n",
        "              lines = f.readlines()\n",
        "              for x in lines:\n",
        "                  words = x.split(\" \")\n",
        "                  xp = float(words[1])\n",
        "                  yp = float(words[2])\n",
        "                  wp = float(words[3])\n",
        "                  hp = float(words[4])\n",
        "                  temp = int(words[0])\n",
        "                  x1 = int(round(xp*width-(wp*width)/2,0))\n",
        "                  x2 = int(round(x1+wp*width,0))\n",
        "                  y1 = int(round(yp*height-(hp*height)/2,0))\n",
        "                  y2 = int(round(y1+hp*height,0))\n",
        "                  words[0] = str(x1)\n",
        "                  words[1] = str(y1)\n",
        "                  words[2] = str(x2)\n",
        "                  words[3] = str(y2)\n",
        "                  if temp == 0:\n",
        "                      words[4] = \"Person\"\n",
        "                  else:\n",
        "                      words[4] = \"Ball\"\n",
        "                  words.insert(0,(\"images/\"+im_name))\n",
        "                  new_lines.append(words[:len(words)-1])\n",
        "      df = pd.DataFrame(new_lines)\n",
        "      df.to_csv(data_dir+'/_annotations.csv', index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlrG8uuGNHY5"
      },
      "source": [
        "create_annotations(\"./LPCV/train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5saZvaC3KuG"
      },
      "source": [
        "create_annotations(\"./LPCV/valid\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqNE_lqVzNF_"
      },
      "source": [
        "!keras_retinanet/bin/train.py --steps 100 --weighted-average csv ./LPCV/train/_annotations.csv ./LPCV/dataset.txt --val-annotations ./LPCV/valid/_annotations.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CLOisOaSql0"
      },
      "source": [
        "!python keras_retinanet/bin/convert_model.py ./snapshots/resnet50_csv_21.h5 ./inference_models/lpcv_inference50.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74yeuaGgUNv4"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet import layers, initializers\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "import pathlib\n",
        "print(tf.version.VERSION)\n",
        "tf.compat.v1.enable_v2_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcOHyl3EcRvw"
      },
      "source": [
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "from keras_retinanet.utils.gpu import setup_gpu\n",
        "from keras.layers import Input\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV8eYzmJUBqs"
      },
      "source": [
        "model =  models.load_model('./lpcv_inference50.h5', backbone_name=\"resnet50\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ow_0AVeqehe"
      },
      "source": [
        "# Code Below Can be used to run the inference model on an image file or a video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRAmDNEsI2q2"
      },
      "source": [
        "labels_to_names = {0: 'Person', 1: 'Ball'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-XFUk1CIcXj"
      },
      "source": [
        "def detect_image(image, model, class_dict, start):\n",
        "  if type(image)==str:\n",
        "    image = read_image_bgr(image)\n",
        "  else:\n",
        "    image = np.ascontiguousarray(Image.fromarray(image).convert('RGB'))\n",
        "    image = image[:, :, ::-1]\n",
        "  # copy to draw on\n",
        "  draw = image.copy()\n",
        "  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "  # preprocess image for network\n",
        "  image = preprocess_image(image)\n",
        "  image, scale = resize_image(image)\n",
        "  # process image\n",
        "  n = time.time()\n",
        "  boxes, scores, labels = model.predict(np.expand_dims(image, axis=0))\n",
        "  print(\"processing time: \", time.time() - n)\n",
        "\n",
        "  # correct for image scale\n",
        "  boxes /= scale\n",
        "  # visualize detections\n",
        "  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "      # scores are sorted so we can break\n",
        "      if score < 0.5:\n",
        "          break\n",
        "          \n",
        "      color = label_color(label)\n",
        "      \n",
        "      b = box.astype(int)\n",
        "      draw_box(draw, b, color=color)\n",
        "      \n",
        "      caption = \"{} {:.3f}\".format(class_dict[label], score)\n",
        "      draw_caption(draw, b, caption)\n",
        "  return draw, time.time() - start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YvcBR4zqxpJ"
      },
      "source": [
        "draw, detect_time = detect_image('shot.png', model, labels_to_names, time.time())\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.axis('off')\n",
        "plt.imshow(draw)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpOsvVZCDcFd"
      },
      "source": [
        "def read_video(video, model, class_dict):\n",
        "  cap = cv2.VideoCapture(video)\n",
        "  frame_width = int(cap.get(3))\n",
        "  frame_height = int(cap.get(4))\n",
        "  frame_size = (frame_width,frame_height)\n",
        "  fps = 60\n",
        "  output_file = \"TESTOUT2\"+video\n",
        "  output = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc(*'XVID'), 60, frame_size)\n",
        "  count = 0\n",
        "  times = []\n",
        "  while(cap.isOpened() and count < 1000):\n",
        "    print(count)\n",
        "    count+=1\n",
        "    ret, frame = cap.read()\n",
        "    if ret == False:\n",
        "      break\n",
        "    timer = 0\n",
        "    start = time.time()\n",
        "    if count%2 == 0:\n",
        "      draw, timer = detect_image(frame, model, class_dict, start)\n",
        "    else:\n",
        "      draw = frame\n",
        "      timer = time.time()-start\n",
        "      print(\"processing time: \", timer)\n",
        "    output.write(draw)\n",
        "    times.append(timer)\n",
        "  cap.release()\n",
        "  output.release()\n",
        "  timeave = np.mean(np.array(times))\n",
        "  print(timeave)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTxpG0WCDr0x"
      },
      "source": [
        "read_video('7p3b_02M.m4v', model, labels_to_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "nE5xlk43c7-A",
        "outputId": "25ec9346-8ff5-4bcd-8f58-c27e5df7f62c"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('TESTOUT7p3b_02M.m4v') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7e28dec9-11b2-43a8-9d10-2364be0be71c\", \"TESTOUT7p3b_02M.m4v\", 1058839303)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx4xgH-GqC6j"
      },
      "source": [
        "# Code Below is Creates and is able to perform inference from a tflite file, however it is slow and inefficient as of now. \n",
        "Inference must be done on a local machine to perform in a reasonable time. Colab is incredibly inneficient and most likely will crash at some point. There is still a scaling issue that must be straightened out in order to draw the boxes correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Pj-I0UZGGO"
      },
      "source": [
        "fixed_input = Input((256,256,3))\n",
        "fixed_model = Model(fixed_input,model(fixed_input))\n",
        "fixed_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU5p9sv0WuPr"
      },
      "source": [
        "def representative_dataset():\n",
        "    for _ in range(100):\n",
        "      data = np.random.rand(1, 256, 256, 3)\n",
        "      yield [data.astype(np.float32)]\n",
        "def convert_model_to_tflite(model_path, filename = \"converted_model.tflite\"):\n",
        "  model = models.load_model(model_path, backbone_name='resnet50')\n",
        "  fixed_input = Input((256,256,3))\n",
        "  fixed_model = Model(fixed_input,model(fixed_input))\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(fixed_model)\n",
        "  # converter.representative_dataset = representative_dataset\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS,\n",
        "  ]\n",
        "  # converter.inference_input_type = tf.int8  # or tf.uint8\n",
        "  # converter.inference_output_type = tf.int8\n",
        "  tflite_model = converter.convert()\n",
        "  open(filename, \"wb\").write(tflite_model)\n",
        "  print(convert_bytes(get_file_size(\"converted_model.tflite\"), \"MB\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMxbhuTXry0"
      },
      "source": [
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size\n",
        "    \n",
        "def convert_bytes(size, unit=None):\n",
        "    if unit == \"KB\":\n",
        "        return print('File size: ' + str(round(size / 1024, 3)) + ' Kilobytes')\n",
        "    elif unit == \"MB\":\n",
        "        return print('File size: ' + str(round(size / (1024 * 1024), 3)) + ' Megabytes')\n",
        "    else:\n",
        "        return print('File size: ' + str(size) + ' bytes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVLIfw97WxaS"
      },
      "source": [
        "convert_model_to_tflite('./lpcv_inference50.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKzHNKtSOWHI"
      },
      "source": [
        "image = \"baseball.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WVFhx7IOnMI"
      },
      "source": [
        "def tflite_inference(image, model):\n",
        "  original_image = read_image_bgr(image)\n",
        "  original_image, scale = resize_image(original_image)\n",
        "  image_data = cv2.resize(original_image, (256,256))\n",
        "  image_data = preprocess_image(image_data)\n",
        "  image_data = np.expand_dims(image_data, axis=0)\n",
        "  interpreter = tf.lite.Interpreter(model_path=model)\n",
        "  input_details = interpreter.get_input_details()\n",
        "  output_details = interpreter.get_output_details()\n",
        "  interpreter.allocate_tensors()\n",
        "  interpreter.set_tensor(input_details[0]['index'], image_data)\n",
        "  start = time.time()\n",
        "  interpreter.invoke()\n",
        "  tot = time.time() - start\n",
        "  scores = interpreter.get_tensor(output_details[0]['index'])\n",
        "  boxes = interpreter.get_tensor(output_details[1]['index'])\n",
        "  labels = interpreter.get_tensor(output_details[2]['index'])\n",
        "  boxes /= scale\n",
        "  draw = original_image.copy()\n",
        "  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "    if score < 0.5:\n",
        "      break\n",
        "    color = label_color(label)\n",
        "    b = box.astype(int)\n",
        "    draw_box(draw, b, color=color)\n",
        "        \n",
        "    caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "    draw_caption(draw, b, caption)\n",
        "  return draw, tot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zBRV11iiVx5"
      },
      "source": [
        "draw, tot_time = tflite_inference('shot.png', 'converted_model.tflite')\n",
        "print(tot_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-5FNz7hcnE5"
      },
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "plt.axis('off')\n",
        "plt.imshow(draw)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}